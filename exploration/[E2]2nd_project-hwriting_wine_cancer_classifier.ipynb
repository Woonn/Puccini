{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 손글씨 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 필요 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits() #데이터 로딩\n",
    "print(type(dir(digits)))\n",
    "digits.keys() #데이터 구성 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### feature데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits_data) # 데이터를 출력해서 형태 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(digits.feature_names) # col은 64개의 픽셀값으로 이루어져 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(digits_data.shape) # 데이터 형태를 확인합니다. 1,797개의 row와 클래스별로 8개씩 8클래스, 64개의 col로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0. 10. 14.  8.  1.  0.  0.  0.  2. 16. 14.  6.  1.  0.  0.  0.  0.\n",
      " 15. 15.  8. 15.  0.  0.  0.  0.  5. 16. 16. 10.  0.  0.  0.  0. 12. 15.\n",
      " 15. 12.  0.  0.  0.  4. 16.  6.  4. 16.  6.  0.  0.  8. 16. 10.  8. 16.\n",
      "  8.  0.  0.  1.  8. 12. 14. 12.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(digits_data[-1]) # 가장 마지막 데이터는 다음과 같이 생겼습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### label data 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names) # 라벨을 나타내는 target data는 0~9로 총 10개로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label = digits.target # 라벨값 저장\n",
    "print(digits_label.shape) # 확인을 위해 출력합니다. 1,797개 row의 ndarray입니다.\n",
    "type(digits_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     1\n",
       "2     2\n",
       "3     3\n",
       "4     4\n",
       "...  ..\n",
       "1792  9\n",
       "1793  0\n",
       "1794  8\n",
       "1795  9\n",
       "1796  8\n",
       "\n",
       "[1797 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(digits_label) # 라벨별로 count 하기위해 panads를 활용하여 DataFrame 형태로 변형하여 저장합니다.\n",
    "df # 이는 class간 데이터수의 편차를 보기 위함입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1797\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "5    182\n",
       "1    182\n",
       "6    181\n",
       "4    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].value_counts() # 데이터는 균등하게 분포하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Classifier로 분류시 warning message가 떠서 정규화 실시\n",
    "* 해당 메시지는 제한된 횟수 내에서 분석을 완료하지 못했을때 뜨는 오류라고 나옴\n",
    "* 따라서 정규화를 해주면 수치가 줄어 횟수역시 줄어든다고 나왔으며, 또 다른 해결책으로는 제한횟수를 늘려주는 방법이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
      " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
      " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
      " ...\n",
      " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
      " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
      " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "transformer = MinMaxScaler()\n",
    "#transformer = MinMaxScaler(feature_range=(0, 1))\n",
    "transformer.fit(digits_data) #MinMaxScaler 모델에 x_train_df 데이터 적용 (최소값, 최대값 계산)\n",
    "\n",
    "digits_data = transformer.transform(digits_data)\n",
    "print(digits_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) train, test  분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits_data, # feature와 target data를 각각 x, y에 입력함\n",
    "                                                   digits_label,\n",
    "                                                   random_state = 7, # 랜덤고정\n",
    "                                                   test_size = 0.2) # 입력한 데이터를 train : test비율 8 : 2로 구분 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### DecicionTree 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * ### 모델 생성의 단계는 모든 classifier에 일괄적용됩니다. \n",
    "    1. classifier 지정\n",
    "    2. train 데이터로 훈련시키기\n",
    "    3. test 데이터로 예측하기\n",
    "    4. 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree분류기 만들기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "d_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(d_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tree.fit(x_train, y_train) # 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = d_tree.predict(x_test) # test하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8555555555555555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred) # accuracy만 확인하기\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred)) # 모든 분류기준 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  3,  1,  0,  1,  1,  0,  0,  2],\n",
       "       [ 0,  0, 33,  2,  0,  0,  1,  1,  2,  1],\n",
       "       [ 0,  1,  0, 31,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0,  1,  0, 35,  0,  0,  0,  1,  0],\n",
       "       [ 0,  1,  0,  0,  0, 27,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0, 26,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  2,  1,  0, 27,  0,  2],\n",
       "       [ 0,  5,  4,  1,  1,  0,  3,  0, 28,  1],\n",
       "       [ 0,  1,  1,  2,  2,  1,  0,  0,  0, 25]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred) # 항목별 실제 예측한 내용 확인, 숫자가 적은건 테스트 데이터이기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### RandomForest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9638888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "r_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "r_forest.fit(x_train, y_train)\n",
    "y_pred = r_forest.predict(x_test)\n",
    "\n",
    "#예측\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1,  0, 27,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 32,  0,  1],\n",
       "       [ 0,  3,  0,  0,  1,  1,  0,  2, 36,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2,  0,  0,  0, 30]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.9888888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred = svm_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 28,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0, 40,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SGDClassifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.93      0.88      0.90        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.94      0.94        34\n",
      "           4       0.95      0.97      0.96        37\n",
      "           5       0.76      1.00      0.86        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.97      0.79      0.87        43\n",
      "           9       0.91      0.91      0.91        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.93       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD_model = SGDClassifier()\n",
    "\n",
    "SGD_model.fit(x_train, y_train)\n",
    "y_pred = SGD_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 37,  0,  1,  0,  2,  0,  0,  0,  2],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 32,  0,  1,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 36,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 26,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0, 32,  0,  0],\n",
       "       [ 0,  2,  1,  1,  1,  3,  0,  1, 34,  0],\n",
       "       [ 0,  0,  0,  0,  0,  3,  0,  0,  0, 29]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### LogisticRegression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.91      0.93      0.92        42\n",
      "           2       0.95      1.00      0.98        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.90      1.00      0.95        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.97      1.00      0.99        33\n",
      "           8       0.95      0.86      0.90        43\n",
      "           9       0.94      0.91      0.92        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "#모델 학습 및 분류확률 확인\n",
    "log_model.fit(x_train, y_train)\n",
    "y_pred = log_model.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* logistic regression classifier에서 기존 코드로는 warning이 뜸\n",
    "* 스케일 차이가 크기 때문에 나타나는 문제로 정규화를 하거나 max_iter로 반복 횟수를 늘려주면 됨\n",
    "* 정규화를 진행해도 같은 warning message가 나타나서 max_iter값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 39,  1,  0,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 26,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  0],\n",
       "       [ 0,  2,  1,  0,  0,  1,  0,  1, 37,  1],\n",
       "       [ 0,  1,  0,  0,  0,  2,  0,  0,  0, 29]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 손글씨 데이터는 0~9까지 10개의 라벨당 약 180개의 데이터가 균등하게 있었습니다.\n",
    "\n",
    "* 8번 라벨이 다소 제대로 분류를 못했지만 적은 수치입니다.\n",
    "\n",
    "* 가장 좋은 성능을 보인 분류기는 SVM classifier였습니다.\n",
    "\n",
    "* 데이터의 분포가 균등해 여러 분류 기준 중 accuracy(전체 예측중 제대로 맞춘 예측의 비율)로 판단해도 될 것입니다.\n",
    "\n",
    "* 따라서 손글씨 분류기로 SVM을 선택하였으며 약 99%의 정확도를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 와인분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 필요 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines = load_wine() #데이터 로딩\n",
    "print(type(dir(wines)))\n",
    "wines.keys() #데이터 구성 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_data = wines.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(wines_data) # 데이터 모양 출력해서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "print(wines_data.shape) # 데이터 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.13   4.1    2.74  24.5   96.     2.05   0.76   0.56   1.35   9.2\n",
      "   0.61   1.6  560.  ]\n"
     ]
    }
   ],
   "source": [
    "print(wines_data[-1]) # 데이터 한개만 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wines.feature_names) # feature_name확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wines_label = wines.target #결과변수 입력\n",
    "print(wines_label.shape)\n",
    "wines_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wines_label)\n",
    "df\n",
    "df[0].value_counts() # 라벨별 데이터 불균형이 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) train, test  분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 2 1 2 0 0 2 2 1 0 1 1 0 0 2 2 2 0 1 1 2 1 2 0 0 0 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#feature와 target을 각각 x, y에 입력함\n",
    "#입력한 데이터를 train : test비율 8 : 2로 구분 \n",
    "#랜덤고정\n",
    "x_train, x_test, y_train, y_test = train_test_split(wines_data,\n",
    "                                                   wines_label,\n",
    "                                                   random_state = 1234,\n",
    "                                                   test_size = 0.2)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### DecicionTree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "#DecisionTree분류기 만들기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "d_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(d_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = d_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.82      1.00      0.90         9\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.90      0.89      0.89        36\n",
      "weighted avg       0.90      0.89      0.89        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix로 모델이 예측한 결과값에 대해 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  2,  0],\n",
       "       [ 0, 15,  2],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### RandomForest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.88      0.94        17\n",
      "           2       0.82      1.00      0.90         9\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.96      0.95        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "r_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "r_forest.fit(x_train, y_train)\n",
    "y_pred = r_forest.predict(x_test)\n",
    "\n",
    "#예측\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0, 15,  2],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "0.6944444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        10\n",
      "           1       0.63      1.00      0.77        17\n",
      "           2       0.50      0.11      0.18         9\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.71      0.60      0.59        36\n",
      "weighted avg       0.70      0.69      0.64        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred = svm_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  2,  1],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  8,  1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVM 모델도 2를 2라고 분류하지 못합니다. 이는 SGD와 유사한 모습을 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SGDClassifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        10\n",
      "           1       0.59      1.00      0.74        17\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.53      0.57      0.52        36\n",
      "weighted avg       0.55      0.67      0.58        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD_model = SGDClassifier()\n",
    "\n",
    "SGD_model.fit(x_train, y_train)\n",
    "y_pred = SGD_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  3,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  9,  0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Warning에 대하여\n",
    "* random_state = 7의 데이터가 유독 SGD에서만 2번 정답레이블이 판단이 어렵게 분류된 듯 합니다. random_state를 재설정해줘도 변하지 않습니다. 여전히 recall, f-1 score는 처참합니다. 2를 제대로 2라고 분류한 경우가 0입니다. 데이터와 모델이 맞지 않는듯 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### LogisticRegression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.95      0.91      0.93        22\n",
      "           2       0.89      1.00      0.94        16\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.95      0.95        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state = 32, max_iter = 5000)\n",
    "\n",
    "#모델 학습 및 분류확률 확인\n",
    "log_model.fit(x_train, y_train)\n",
    "y_pred = log_model.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  1,  0],\n",
       "       [ 0, 20,  2],\n",
       "       [ 0,  0, 16]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* decision tree에서는 1번 라벨과 2번 라벨 사이의 트레이드오프가 관찰됩니다.\n",
    "* 해당 분류문제는 단순히 와인을 판별하는 문제이며 데이터가 불균형한 특징을 보입니다. 따라서 데이터 불균형을 해소할 수 있는 f1-score를 선택하는 것이 바람직해 보입니다.\n",
    "* 일부 선형 기반 모형(SVM, SGD)의 경우 예측율이 매우 낮게 나왔습니다. 가장 높은 예측률을 보인 것은 random forest 분류기였습니다. \n",
    "* 모든 수치가 동일하지만 데이터가 불균형하기 때문에 와인 분류기로 random forest의 (precision과 recall의 조화평균인)f1-score의 macro avg score를 선택했습니다. accuracy = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 유방암데이터 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 필요 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(type(dir(cancer)))\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "(569, 30)\n",
      "[7.760e+00 2.454e+01 4.792e+01 1.810e+02 5.263e-02 4.362e-02 0.000e+00\n",
      " 0.000e+00 1.587e-01 5.884e-02 3.857e-01 1.428e+00 2.548e+00 1.915e+01\n",
      " 7.189e-03 4.660e-03 0.000e+00 0.000e+00 2.676e-02 2.783e-03 9.456e+00\n",
      " 3.037e+01 5.916e+01 2.686e+02 8.996e-02 6.444e-02 0.000e+00 0.000e+00\n",
      " 2.871e-01 7.039e-02]\n",
      "['malignant' 'benign']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = cancer.data\n",
    "cancer_labels = cancer.target\n",
    "print(cancer.feature_names)\n",
    "print(cancer_data)\n",
    "print(cancer_data.shape)\n",
    "print(cancer_data[-1])\n",
    "print(cancer.target_names)\n",
    "df = pd.DataFrame(cancer_labels)\n",
    "df\n",
    "df[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) train, test  분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(cancer_data,\n",
    "                                                    cancer_labels,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### DecicionTree 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_tree = DecisionTreeClassifier(random_state=32)\n",
    "print(d_tree._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = d_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33,  7],\n",
       "       [ 3, 71]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### RandomForest 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "r_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "r_forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = r_forest.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_prod = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### SGDClassifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        40\n",
      "           1       0.86      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.93      0.85      0.87       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD_model = SGDClassifier(random_state=32)\n",
    "\n",
    "SGD_model.fit(x_train, y_train)\n",
    "y_pred = SGD_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 12],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### LogisticRegression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=32, max_iter = 2000) # max_iter = 반복횟수 제한\n",
    "\n",
    "log_model.fit(x_train, y_train)\n",
    "y_pred = log_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34,  6],\n",
       "       [ 0, 74]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 모델을 평가해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 유방암 데이터도 불균형했습니다.(357:212)\n",
    "* 분류기중에는 random forest와 SVM분류기가 오류 없이 모든 항목을 분류하였습니다.\n",
    "* precision은 True라고 판단한 것 중에 실제로 true인 경우입니다. recall은 실제 True인 것 중 true라고 판단한 경우입니다. 바꿔말하자면  Precision가 높으려면 음성인데 양성으로 판단하는 경우가 적어야 하며, Recall이 높으려면 양성인데 음성으로 판단한 경우가 적어야 합니다.\n",
    "* 해당 데이터는 유방암 양성여부를 판단하는 것으로, 이런 유형의 데이터는 양성인데 음성으로 판단한 경우가 있으면 치명적입니다. 따라서 recall score를 적용하는게 좋아보입니다.\n",
    "* 해당 데이터는 이진 분류로 보다 직관적으로 해석이 가능한 SVM 모델의 recall의 macro avg score로 판단하는게 좋아보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고..\n",
    "* 각 모델에 대한 평가와 코드에 대한 설명은 각 데이터별로 서술해 놓았습니다.\n",
    "\n",
    "\n",
    "* 이번 노드에서 가장 신경썼던 부분은 전체적인 프로세스를 일반화 하는 것, 그리고 평가지표를 어떻게 설정할 것인지에 대한 문제였습니다. \n",
    "  * 우선 코드를 반복 작성하다보니, 불러오는 classifier만 달라지고, 데이터를 불러와서 탐색하고, feature data와 target data를 구분하고, 테스트와 트레인셋으로 split한 후, fit으로 훈련시키고, predict로 예측한 후, 이를 시각화하여 평가지표를 판단하는 프로세스가 눈에 들어왔습니다. 반복 수행하며 익숙해지기 위해 노력했습니다.\n",
    "  * 두번째는 평가지표의 설정에 대한 문제였습니다. 단어부터 생소해 각 지표들의 개념을 우선 숙지한 후, label을 DataFrame으로 만들어 각 정답별 수를 체크해 이를 하나의 판단 기준으로 삼았습니다. (일반적으로 데이터가 불균형한 경우, F1 score을 사용하며 macro avg로 판단하는것이 좋다고 합니다)\n",
    "  * 또 배운내용 중 recall과 precicion score에 대한 내용 역시 판단의 기준으로 삼아 데이터의 성격에 따른 판단기준으로 만들었습니다.(암과 같이 음성오분류가 위험한 경우 : recall / 스팸분류처럼 양성오분류가 위험한 경우 : precision으로 이해했습니다.\n",
    "  * 와인 분류 데이터의 경우, 총 데이터 178개, 라벨별 0 : 59개, 1 : 71개, 2 : 48개로 데이터 수도 적고, 라벨별 격차도 보였습니다. 이런 경우 SVM과 SGD classifier의 성능이 급격히 떨어졌습니다.(에러 : 라벨 2의 판단을 할 수 없음) 개선을 위해 random_state도 다양하게 바꿔보고, train-test셋 간의 비율도 조정해 보았지만, 데이터가 워낙 작아 별 효과가 없었습니다.\n",
    "\n",
    "\n",
    "\n",
    "* 프로세스는 단순했지만 생각보다 많은것을 생각하고 판단해야 한다는 것을 알게되었고 공부를 할수록 많은것을 할 수 있을것이라는 생각이 들었습니다.열심히 해보겠습니다. 감사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
